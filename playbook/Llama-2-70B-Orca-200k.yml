---
- name: Setup Default 
  import_playbook: default.yml

- name: Install Llama2 70B Orca 200k for use with llama.cpp
  hosts: all
  vars:
    model_dir: "{{ llm_model_dir }}/Llama-2-70B-Orca-200k"
    aria2_list: "model.list"
    llama_dir: "{{ llm_git_dir }}/llama.cpp"

  roles:
    - name: Install llama.cpp
      role: llama.cpp
      vars: 
        llama_dir: "{{ llm_git_dir }}/llama.cpp"

  tasks:
    - name: Verify variables
      debug: 
        msg:
         - "llama_dir: {{ llama_dir }}"
         - "src_model_dir: {{ src_model_dir }}"
         - "model_dir: {{ model_dir }}"
         - "aria2_list: {{ aria2_list }}"

    - name: Create Model dir
      file:
        path: "{{ model_dir }}"
        state: directory

    - name: Verify deployed modle file list
      file:
        path: "{{ model_dir }}/{{ aria2_list }}"
        state: file

    - name: Fetch Model Parameters
      shell:
        cmd: "aria2c --input-file '{{ aria2_list }}' -x 16 -j 16 -s 16 -c"
        chdir: "{{ model_dir }}"

    - name: Example usage
      debug:
        msg: 
          - "cd {{ llama_dir }}"
          - "./main --threads 14 --model {{ model_dir }}/<model>.gguf --file {{ llm_prompt_dir }}/instruct/ansible.txt"
        
